src.rag_toolkit.core.llm.base
=============================

.. py:module:: src.rag_toolkit.core.llm.base

.. autoapi-nested-parse::

   Base Protocol for LLM clients.



Classes
-------

.. autoapisummary::

   src.rag_toolkit.core.llm.base.LLMClient
   src.rag_toolkit.core.llm.base.ChatMessage


Module Contents
---------------

.. py:class:: LLMClient

   Bases: :py:obj:`Protocol`


   Protocol for Large Language Model clients.

   Uses Protocol instead of ABC for more flexible duck typing.
   Any class implementing these methods can be used as an LLMClient.


   .. py:method:: generate(prompt, **kwargs)

      Generate a completion from a prompt.

      :param prompt: The input prompt
      :param \*\*kwargs: Additional parameters (temperature, max_tokens, etc.)

      :returns: Generated text completion



   .. py:method:: generate_batch(prompts, **kwargs)

      Optional batch generation.

      Default implementation iterates generate() for each prompt.
      Implementations can override for batch optimization.

      :param prompts: Iterable of input prompts
      :param \*\*kwargs: Additional parameters

      :Yields: Generated text completions



   .. py:property:: model_name
      :type: str


      Return the underlying model name.


.. py:class:: ChatMessage

   Bases: :py:obj:`Dict`\ [\ :py:obj:`str`\ , :py:obj:`str`\ ]


   Typed alias for chat messages (role/content).


   .. py:attribute:: role
      :type:  str


   .. py:attribute:: content
      :type:  str


