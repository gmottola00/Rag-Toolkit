src.rag_toolkit.infra.llm.openai
================================

.. py:module:: src.rag_toolkit.infra.llm.openai

.. autoapi-nested-parse::

   OpenAI-based LLM client.



Classes
-------

.. autoapisummary::

   src.rag_toolkit.infra.llm.openai.OpenAILLMClient


Module Contents
---------------

.. py:class:: OpenAILLMClient(*, model = DEFAULT_OPENAI_MODEL, api_key = DEFAULT_OPENAI_API_KEY, base_url = DEFAULT_OPENAI_BASE_URL)

   Bases: :py:obj:`rag_toolkit.core.llm.base.LLMClient`


   Client for OpenAI chat completions.


   .. py:attribute:: client


   .. py:property:: model_name
      :type: str


      Return the underlying model name.


   .. py:method:: generate(prompt, **kwargs)

      Generate a completion from a prompt.

      :param prompt: The input prompt
      :param \*\*kwargs: Additional parameters (temperature, max_tokens, etc.)

      :returns: Generated text completion



   .. py:method:: generate_batch(prompts, **kwargs)

      Optional batch generation.

      Default implementation iterates generate() for each prompt.
      Implementations can override for batch optimization.

      :param prompts: Iterable of input prompts
      :param \*\*kwargs: Additional parameters

      :Yields: Generated text completions



